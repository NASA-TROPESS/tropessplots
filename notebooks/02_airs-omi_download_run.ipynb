{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790ba139",
   "metadata": {},
   "source": [
    "# Create TROPESS AIRS-OMI Daily Plots\n",
    "\n",
    "## Overview\n",
    "This notebook will allow you to download [TROPESS](https://tes.jpl.nasa.gov/tropess) AIRS-OMI data and then use that data to create daily plots for a given date.  \n",
    "The following suite of plots will be created from standard and summary data products:\n",
    "\n",
    "| Species | Standard Product | Summary Product |\n",
    "| :------ | :------ | :------ |\n",
    "| Ozone (O3) | TRPSDL2O3AIRSOMIFS.1 | TRPSYL2O3AIRSOMIFS.1 |\n",
    "\n",
    "In the table above, the \"short name\" of the data products is listed (e.g., \"TRPSYL2O3AIRSOMIFS.1\").  Short names are assigned by a NASA DAAC (in this case, the GES-DISC)\n",
    "for each data products as a way to lookup or refer to a product with out using the product's full long name (e.g., \"TROPESS AIRS-Aqua and OMI-Aura L2 Ozone for Reanalysis Stream, Summary Product V1\").  You'll see these short names in the code below when there are blocks looping through the different products.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "This notebook uses the [GES-DISC's](https://disc.gsfc.nasa.gov) simple subset service to retrieve requested data.  It requires a [NASA Earthdata login](https://urs.earthdata.nasa.gov/).  Please make sure you have one before attempting to run this notebook.  Also make sure you've setup a `.netrc` file in your home directory with your NASA Earthata login information.  You can use the follow steps to generate that file, if needed:\n",
    "\n",
    "```sh\n",
    "cd ~\n",
    "touch .netrc\n",
    "echo \"machine urs.earthdata.nasa.gov login uid_goes_here password password_goes_here\" > .netrc\n",
    "chmod 0600 .netrc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c15951",
   "metadata": {},
   "source": [
    "## Import Libraries \n",
    "\n",
    "Standard (i.e., available through pip) libraries `datetime`, `requests`, `os`, and `glob` are imported below.  You will also need to clone or install the `tropessplots` library if you haven't already.  It is available at [https://github.com/NASA-TROPESS/tropessplots](https://github.com/NASA-TROPESS/tropessplots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import requests\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from tropessplots.io.airs_omi import read_l2summary, read_l2standard\n",
    "from tropessplots.website_plots.airs_omi import plot_daily_overview\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a05561a",
   "metadata": {},
   "source": [
    "## Setup Global Variables\n",
    "\n",
    "Please edit the variables in the next block as needed.  We'll do some checks and conversions after those variables are\n",
    "set to reformat the date so we can use it in later blocks and to create any directories that don't exist.  We also have a \n",
    "list of all the data products we want to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c988c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The date you want to plot in YYYYMMDD format.\n",
    "DATE = '20250901'\n",
    "\n",
    "# Where you want to store the data you download.\n",
    "DOWNLOAD_DIRECTORY = '/tmp/download'\n",
    "\n",
    "# Where you want to store the plot outputs.\n",
    "PLOT_DIRECTORY = '/tmp/download'\n",
    "\n",
    "# A list of the species you want to plot.  All species are listed here\n",
    "# by default.  Edits to this list (additions or subtractions) will be \n",
    "# reflected in the SHORT_NAME_LIST variable below.  \n",
    "SPECIES_ARRAY = ['O3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The short names of the data products you want to plot.  These are automatically\n",
    "# generated from SPECIES_ARRAY above.  Do not manually edit this list.\n",
    "SHORT_NAME_LIST = []\n",
    "\n",
    "if 'O3' in SPECIES_ARRAY:\n",
    "    SHORT_NAME_LIST.append('TRPSDL2O3AIRSOMIFS.1')\n",
    "    SHORT_NAME_LIST.append('TRPSYL2O3AIRSOMIFS.1')\n",
    "\n",
    "# Formatting dates for use later\n",
    "date_object = dt.datetime.strptime(DATE, '%Y%m%d')\n",
    "iso_start_date = date_object.strftime('%Y-%m-%dT00:00:00.000Z')\n",
    "iso_end_date = date_object.strftime('%Y-%m-%dT23:59:59.000Z')\n",
    "\n",
    "# Create directories if they don't already exist\n",
    "os.makedirs(DOWNLOAD_DIRECTORY, exist_ok=True)\n",
    "os.makedirs(PLOT_DIRECTORY, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df30d9f",
   "metadata": {},
   "source": [
    "## Search for Data\n",
    "\n",
    "Now that we are setup, we're going to start our work by downloading data from the GES-DISC.  We'll\n",
    "make a request to the GES-DISC service to search for the data product and date we want.\n",
    "Then we'll check to see if the serivce has found what we are looking for.  If not, we'll keep\n",
    "waiting until it's found (if it takes too long though, we'll error out).  Once the service returns with a \n",
    "list of files we requested, we'll get a list of the URLs where the files are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "for short_name in SHORT_NAME_LIST:\n",
    "     # Send a request to the GES-DISC to search for files for the day\n",
    "     # Again, you do need a NASA Earthdata account and a .netrc file in your home\n",
    "     # directory to eventually download data found in these requests.\n",
    "    r = requests.post('https://disc.gsfc.nasa.gov/service/subset/jsonwsp', \n",
    "                        json={\"methodname\": \"subset\", \"args\": {\"role\":\"subset\",\"start\":iso_start_date, \n",
    "                                                            \"end\":iso_end_date,\n",
    "                                                            \"data\":[{\"datasetId\":short_name.replace('.', '_')}]}}, \n",
    "                        headers={\"Accept\": \"application/json, text/plain, */*\", \n",
    "                                \"Content-type\": \"application/json;charset=utf-8\"})\n",
    "\n",
    "    r.status_code\n",
    "    info = r.json()\n",
    "    status_counter = 0\n",
    "    breaker_counter = 0\n",
    "\n",
    "    # Get the status of the request; if not done, try again a few times\n",
    "    while status_counter == 0:\n",
    "        r = requests.post('https://disc.gsfc.nasa.gov/service/subset/jsonwsp', \n",
    "                    json={\"methodname\": \"GetStatus\", \"args\": {\"jobId\": info['result']['jobId'], \"sessionId\": info['result']['sessionId'] }, \n",
    "                                                                \"type\": \"jsonwsp/request\", \"version\": \"1.0\"}, \n",
    "                    headers={\"Accept\": \"application/json, text/plain, */*\", \n",
    "                            \"Content-type\": \"application/json;charset=utf-8\"})\n",
    "        status_info = r.json()\n",
    "        if status_info['result']['Status'] == 'Succeeded' and status_info['result']['PercentCompleted'] == 100:    \n",
    "            status_counter = 1\n",
    "        elif breaker_counter > 50:\n",
    "            print('Not finding any files for this date %s' % DATE)\n",
    "            break\n",
    "        else:\n",
    "            breaker_counter += 1\n",
    "\n",
    "    r = requests.post('https://disc.gsfc.nasa.gov/service/subset/jsonwsp', \n",
    "                        json={\"methodname\": \"GetResult\", \"args\": {\"jobId\": info['result']['jobId'], \"sessionId\": info['result']['sessionId'] }, \n",
    "                                                                        \"type\": \"jsonwsp/request\", \"version\": \"1.0\"}, \n",
    "                        headers={\"Accept\": \"application/json, text/plain, */*\", \n",
    "                                    \"Content-type\": \"application/json;charset=utf-8\"})\n",
    "    link_info = r.json()\n",
    "\n",
    "    # Extract the individual URLs of each file\n",
    "    for this_info in link_info['result']['items']:\n",
    "        if short_name in this_info['label']:\n",
    "            print('Found file %s' % this_info['link'])\n",
    "            files.append(this_info['link'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799eabf7",
   "metadata": {},
   "source": [
    "## Download the Data\n",
    "\n",
    "Now that we have a list of URLs for the files we are interested in, we will download them\n",
    "to our local system to the place we set in the DOWNLOAD_DIRECTORY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05611a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download each file locally.\n",
    "for this_file in files:\n",
    "    r = requests.get(this_file, allow_redirects=True)\n",
    "    open(DOWNLOAD_DIRECTORY + '/' + this_file.split('/')[-1], 'wb').write(r.content)\n",
    "    print('Downloaded %s' % this_file.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c2f2d",
   "metadata": {},
   "source": [
    "## Plot the Data\n",
    "\n",
    "Based on the `SHORT_NAMES_LIST` global variable, we'll crete an array of species names that we're going to plot.  We'll use the standard files for the plotting function, along with the summary files if they exist for that specific species.\n",
    "\n",
    "First, we'll find the standard and summary files on the local system.  Then we'll read the data with the readers we imported from the `tropessplots` library. Then, finally, we will plot the data, again with a plotting function from `tropessplots`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "for species in SPECIES_ARRAY:    \n",
    "    \n",
    "    # Find files\n",
    "    l2summary_file = glob.glob(DOWNLOAD_DIRECTORY + '/*AIRS*OMI*Summary*' + species+'*' + DATE + '*.nc')\n",
    "    l2standard_file = glob.glob(DOWNLOAD_DIRECTORY + '/*AIRS*OMI*Standard*' + species + '*' + DATE + '*.nc')\n",
    "    figure_file = PLOT_DIRECTORY + '/TROPESS_AIRS-OMI_' + species + '_' + DATE + '.png'\n",
    "    \n",
    "    # Read data\n",
    "    l2summary = read_l2summary(files=l2summary_file,\n",
    "                                   verbose=0)\n",
    "    l2standard = read_l2standard(files=l2standard_file,\n",
    "                                 verbose=0)\n",
    "    \n",
    "    # Run plotting routine\n",
    "    plot_daily_overview(l2summary=l2summary,\n",
    "                        l2standard=l2standard,\n",
    "                        file_out=figure_file)\n",
    "    print('Produced plot %s' % figure_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
